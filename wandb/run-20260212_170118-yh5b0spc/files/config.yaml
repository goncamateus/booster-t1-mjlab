_current_progress_remaining:
    value: 1
_custom_logger:
    value: "False"
_episode_num:
    value: 0
_last_episode_starts:
    value: |-
        [ True  True  True  True  True  True  True  True  True  True  True  True
          True  True  True  True  True  True  True  True  True  True  True  True
          True  True  True  True  True  True  True  True]
_last_obs:
    value: |-
        [[ 0.64152228  1.07362425 -0.08828637 ...  0.00264631  0.09399121
          -0.0246658 ]
         [ 0.77014373  1.06772378 -0.05625385 ... -0.0429564  -0.0402661
           0.06320368]
         [ 0.64860252  0.95278544  0.0934135  ... -0.01805917  0.03159422
          -0.01797749]
         ...
         [ 0.65077172  1.08901302  0.09025589 ... -0.06801031  0.06255671
           0.07074196]
         [ 0.60592397  1.0201472  -0.00516813 ... -0.01875895 -0.09489215
          -0.00870255]
         [ 0.60613291  1.0420621   0.03229443 ...  0.08740798  0.09104506
          -0.08945364]]
_last_original_obs:
    value: None
_logger:
    value: <stable_baselines3.common.logger.Logger object at 0x7f4970234d10>
_n_updates:
    value: 0
_num_timesteps_at_start:
    value: 0
_stats_window_size:
    value: 100
_total_timesteps:
    value: 1000000
_vec_normalize_env:
    value: None
_wandb:
    value:
        cli_version: 0.24.2
        code_path: code/train.py
        e:
            4qcaw9pfzvszysp15wjbyvdcfq3b0lxy:
                codePath: train.py
                codePathLocal: train.py
                cpu_count: 6
                cpu_count_logical: 12
                cudaVersion: "13.0"
                disk:
                    /:
                        total: "915230306304"
                        used: "315021930496"
                email: mgm4@cin.ufpe.br
                executable: /home/mateus/rc_humanoid/.venv/bin/python3
                gpu: NVIDIA GeForce RTX 3060
                gpu_count: 1
                gpu_nvidia:
                    - architecture: Ampere
                      cudaCores: 3584
                      memoryTotal: "12884901888"
                      name: NVIDIA GeForce RTX 3060
                      uuid: GPU-628e3a35-04c2-7e52-67e4-cc3a3d8afa9b
                host: pop-os
                memory:
                    total: "33572884480"
                os: Linux-6.18.7-76061807-generic-x86_64-with-glibc2.39
                program: /home/mateus/rc_humanoid/train.py
                python: CPython 3.11.14
                root: /home/mateus/rc_humanoid
                startedAt: "2026-02-12T20:01:18.543624Z"
                writerId: 4qcaw9pfzvszysp15wjbyvdcfq3b0lxy
        m: []
        python_version: 3.11.14
        t:
            "1":
                - 1
            "2":
                - 1
            "3":
                - 1
                - 2
                - 3
                - 16
                - 22
                - 35
            "4": 3.11.14
            "5": 0.24.2
            "12": 0.24.2
            "13": linux-x86_64
action_noise:
    value: None
action_space:
    value: |-
        Box([-1.57 -0.35 -3.31 -1.74 -2.27 -2.44 -3.31 -1.57 -2.27  0.   -1.57 -1.8
         -0.2  -1.    0.   -0.87 -0.44 -1.8  -1.57 -1.    0.   -0.87 -0.44], [1.57 1.22 1.22 1.57 2.27 0.   1.22 1.74 2.27 2.44 1.57 1.57 1.57 1.
         2.34 0.35 0.44 1.57 0.2  1.   2.34 0.35 0.44], (23,), float32)
algo:
    value: PPO
batch_size:
    value: 64
clip_range:
    value: FloatSchedule(ConstantSchedule(val=0.2))
clip_range_vf:
    value: None
device:
    value: cuda
ent_coef:
    value: 0
env:
    value: <stable_baselines3.common.vec_env.subproc_vec_env.SubprocVecEnv object at 0x7f4976172e10>
ep_info_buffer:
    value: deque([], maxlen=100)
ep_success_buffer:
    value: deque([], maxlen=100)
gae_lambda:
    value: 0.95
gamma:
    value: 0.99
learning_rate:
    value: 0.0003
lr_schedule:
    value: FloatSchedule(ConstantSchedule(val=0.0003))
max_grad_norm:
    value: 0.5
model_path:
    value: ./models/booster_ppo_final
n_envs:
    value: 32
n_epochs:
    value: 10
n_steps:
    value: 2048
normalize_advantage:
    value: "True"
num_timesteps:
    value: 0
observation_space:
    value: Box(-inf, inf, (57,), float64)
policy:
    value: |-
        ActorCriticPolicy(
          (features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (pi_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (vf_features_extractor): FlattenExtractor(
            (flatten): Flatten(start_dim=1, end_dim=-1)
          )
          (mlp_extractor): MlpExtractor(
            (policy_net): Sequential(
              (0): Linear(in_features=57, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
            (value_net): Sequential(
              (0): Linear(in_features=57, out_features=64, bias=True)
              (1): Tanh()
              (2): Linear(in_features=64, out_features=64, bias=True)
              (3): Tanh()
            )
          )
          (action_net): Linear(in_features=64, out_features=23, bias=True)
          (value_net): Linear(in_features=64, out_features=1, bias=True)
        )
policy_class:
    value: <class 'stable_baselines3.common.policies.ActorCriticPolicy'>
policy_kwargs:
    value: '{}'
rollout_buffer:
    value: <stable_baselines3.common.buffers.RolloutBuffer object at 0x7f4971f5d4d0>
rollout_buffer_class:
    value: <class 'stable_baselines3.common.buffers.RolloutBuffer'>
rollout_buffer_kwargs:
    value: '{}'
sde_sample_freq:
    value: -1
seed:
    value: None
start_time:
    value: 1770926491292821970
target_kl:
    value: None
tensorboard_log:
    value: ./logs/
test:
    value: false
timesteps:
    value: 1000000
use_sde:
    value: "False"
verbose:
    value: 1
vf_coef:
    value: 0.5
